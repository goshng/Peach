% This file was created with JabRef 2.7.2.
% Encoding: ISO8859_1

@ARTICLE{Altendorf2011,
  author = {Altendorf, Hellen and Jeulin, Dominique},
  title = {Random-walk-based stochastic modeling of three-dimensional fiber
	systems.},
  journal = {Phys Rev E Stat Nonlin Soft Matter Phys},
  year = {2011},
  volume = {83},
  pages = {041804},
  number = {4 Pt 1},
  month = {Apr},
  __markedentry = {[goshng:6]},
  abstract = {For the simulation of fiber systems, there exist several stochastic
	models: systems of straight nonoverlapping fibers, systems of overlapping
	bending fibers, or fiber systems created by sedimentation. However,
	there is a lack of models providing dense, nonoverlapping fiber systems
	with a given random orientation distribution and a controllable level
	of bending. We introduce a new stochastic model in this paper that
	generalizes the force-biased packing approach to fibers represented
	as chains of balls. The starting configuration is modeled using random
	walks, where two parameters in the multivariate von Mises-Fisher
	orientation distribution control the bending. The points of the random
	walk are associated with a radius and the current orientation. The
	resulting chains of balls are interpreted as fibers. The final fiber
	configuration is obtained as an equilibrium between repulsion forces
	avoiding crossing fibers and recover forces ensuring the fiber structure.
	This approach provides high volume fractions up to 72.0075\%.},
  institution = {Department of Image Processing, Fraunhofer Institute of Industrial
	Mathematics, Fraunhofer-Platz 1, D-67663 Kaiserslautern, Germany.
	Hellen.Altendorf@mines-paristech.fr},
  language = {eng},
  medline-pst = {ppublish},
  owner = {goshng},
  pmid = {21599195},
  review = {From a search for simulation of the von mises fisher distribution},
  timestamp = {2012.05.10}
}

@ARTICLE{Chen2010,
  author = {Chen, Gong and Zhou, Qing},
  title = {Heterogeneity in DNA multiple alignments: modeling, inference, and
	applications in motif finding.},
  journal = {Biometrics},
  year = {2010},
  volume = {66},
  pages = {694--704},
  number = {3},
  month = {Sep},
  abstract = {Transcription factors bind sequence-specific sites in DNA to regulate
	gene transcription. Identifying transcription factor binding sites
	(TFBSs) is an important step for understanding gene regulation. Although
	sophisticated in modeling TFBSs and their combinatorial patterns,
	computational methods for TFBS detection and motif finding often
	make oversimplified homogeneous model assumptions for background
	sequences. Since nucleotide base composition varies across genomic
	regions, it is expected to be helpful for motif finding to incorporate
	the heterogeneity into background modeling. When sequences from multiple
	species are utilized, variation in evolutionary conservation violates
	the common assumption of an identical conservation level in multiple
	alignments. To handle both types of heterogeneity, we propose a generative
	model in which a segmented Markov chain is used to partition a multiple
	alignment into regions of homogeneous nucleotide base composition
	and a hidden Markov model (HMM) is employed to account for different
	conservation levels. Bayesian inference on the model is developed
	via Gibbs sampling with dynamic programming recursions. Simulation
	studies and empirical evidence from biological data sets reveal the
	dramatic effect of background modeling on motif finding, and demonstrate
	that the proposed approach is able to achieve substantial improvements
	over commonly used background models.},
  doi = {10.1111/j.1541-0420.2009.01362.x},
  institution = {Department of Statistics, University of California, Los Angeles,
	Los Angeles, California 90095, USA.},
  keywords = {Base Sequence; Bayes Theorem; Binding Sites; Biometry, methods; Conserved
	Sequence; Markov Chains; Sequence Alignment; Transcription Factors,
	metabolism},
  language = {eng},
  medline-pst = {ppublish},
  owner = {goshng},
  pii = {BIOM1362},
  pmid = {19995355},
  timestamp = {2012.05.10},
  url = {http://dx.doi.org/10.1111/j.1541-0420.2009.01362.x}
}

@ARTICLE{Holmes2001,
  author = {Holmes, I. and Bruno, W. J.},
  title = {Evolutionary HMMs: a Bayesian approach to multiple alignment.},
  journal = {Bioinformatics},
  year = {2001},
  volume = {17},
  pages = {803--820},
  number = {9},
  month = {Sep},
  abstract = {We review proposed syntheses of probabilistic sequence alignment,
	profiling and phylogeny. We develop a multiple alignment algorithm
	for Bayesian inference in the links model proposed by Thorne et al.
	(1991, J. Mol. Evol., 33, 114-124). The algorithm, described in detail
	in Section 3, samples from and/or maximizes the posterior distribution
	over multiple alignments for any number of DNA or protein sequences,
	conditioned on a phylogenetic tree. The individual sampling and maximization
	steps of the algorithm require no more computational resources than
	pairwise alignment.We present a software implementation (Handel)
	of our algorithm and report test results on (i) simulated data sets
	and (ii) the structurally informed protein alignments of BAliBASE
	(Thompson et al., 1999, Nucleic Acids Res., 27, 2682-2690).We find
	that the mean sum-of-pairs score (a measure of residue-pair correspondence)
	for the BAliBASE alignments is only 13\% lower for Handelthan for
	CLUSTALW(Thompson et al., 1994, Nucleic Acids Res., 22, 4673-4680),
	despite the relative simplicity of the links model (CLUSTALW uses
	affine gap scores and increased penalties for indels in hydrophobic
	regions). With reference to these benchmarks, we discuss potential
	improvements to the links model and implications for Bayesian multiple
	alignment and phylogenetic profiling.The source code to Handelis
	freely distributed on the Internet at http://www.biowiki.org/Handel
	under the terms of the GNU Public License (GPL, 2000, http://www.fsf.org./copyleft/gpl.html).},
  institution = {Group T10, Los Alamos National Laboratory, NM 87545, USA. ihh@fruitfly.org},
  keywords = {Algorithms; Bayes Theorem; Computer Simulation; Databases, Protein;
	Evolution, Molecular; Humans; Markov Chains; Models, Statistical;
	Proteins, chemistry; Sequence Alignment, methods/statistics /&/ numerical
	data; Sequence Analysis, DNA, statistics /&/ numerical data; Software},
  language = {eng},
  medline-pst = {ppublish},
  owner = {goshng},
  pmid = {11590097},
  timestamp = {2012.05.10}
}

@ARTICLE{Scott2006,
  author = {Scott, Clayton and Nowak, Robert},
  title = {Robust contour matching via the order-preserving assignment problem.},
  journal = {IEEE Trans Image Process},
  year = {2006},
  volume = {15},
  pages = {1831--1838},
  number = {7},
  month = {Jul},
  __markedentry = {[goshng:]},
  abstract = {A common approach to determining corresponding points on two shapes
	is to compute the cost of each possible pairing of points and solve
	the assignment problem (weighted bipartite matching) for the resulting
	cost matrix. We consider the problem of solving for point correspondences
	when the shapes of interest are each defined by a single, closed
	contour. A modification of the standard assignment problem is proposed
	whereby the correspondences are required to preserve the ordering
	of the points induced from the shapes' contours. Enforcement of this
	constraint leads to significantly improved correspondences. Robustness
	with respect to outliers and shape irregularity is obtained by required
	only a fraction of feature points to be matched. Furthermore, the
	minimum matching size may be specified in advance. We present efficient
	dynamic programming algorithms to solve the proposed optimization
	problem. Experiments on the Brown and MPEG-7 shape databases demonstrate
	the effectiveness of the proposed method relative to the standard
	assignment problem.},
  institution = {Department of Statistics, Rice University, Houston, TX 77005, USA.
	cscott@rice.edu},
  keywords = {Algorithms; Artificial Intelligence; Computer Graphics; Image Enhancement,
	methods; Image Interpretation, Computer-Assisted, methods; Information
	Storage and Retrieval, methods; Numerical Analysis, Computer-Assisted;
	Pattern Recognition, Automated, methods; Signal Processing, Computer-Assisted;
	Subtraction Technique; Video Recording, methods},
  language = {eng},
  medline-pst = {ppublish},
  owner = {goshng},
  pmid = {16830905},
  timestamp = {2012.05.10}
}

@ARTICLE{Strange2010,
  author = {Strange, Daniel G T. and Fisher, Sandie T. and Boughton, Philip C.
	and Kishen, Thomas J. and Diwan, Ashish D.},
  title = {Restoration of compressive loading properties of lumbar discs with
	a nucleus implant-a finite element analysis study.},
  journal = {Spine J},
  year = {2010},
  volume = {10},
  pages = {602--609},
  number = {7},
  month = {Jul},
  __markedentry = {[goshng:6]},
  abstract = {Discectomy is a common procedure for treating sciatica. However, both
	the operation and preceding herniated disc alter the biomechanical
	properties of the spinal segment. The disc mechanics are also altered
	in patients with chronic contained herniation. The biomechanical
	properties of the disc can potentially be restored with an elastomeric
	nucleus replacement implanted via minimally invasive surgery.The
	purpose of this study was to determine whether the compressive characteristics
	of the intervertebral disc after a nucleotomy can be restored with
	an elastomeric nucleus replacement.A finite element model of the
	L4-L5 intervertebral disc was created to investigate the effect of
	the implantation of an elastomeric nucleus replacement on the biomechanical
	properties of the disc under axial loading.A L4-L5 physiologic intervertebral
	disc model was constructed and then modified to contain a range by
	volume of nucleotomies and nucleus replacements. The material properties
	of the nucleus replacement were based on experimental data for an
	elastomeric implant. The compressive stiffness, radial annular bulge,
	and stress distribution of the nucleotomy and nucleus replacement
	models were investigated under displacement-controlled loading.Removal
	of nucleus pulposus from the physiologic disc reduced the force necessary
	to compress the disc 2 mm by 50\%, altered the von Mises stress distribution,
	and reduced the outward radial annular bulge. Replacing the natural
	nucleus pulposus of the physiologic disc with an artificial nucleus
	reduced the force required to compress the disc 2 mm by 10\%, indicating
	a restoration of disc compressive stiffness. The von Mises stress
	distribution and annular bulge observed in the disc with an artificial
	nucleus were similar to that observed in the physiologic disc.This
	study demonstrates that despite having different material properties,
	a nucleus replacement implant can restore the axial compressive mechanical
	properties of a disc after a discectomy. The implant carries compressive
	load and transfers the load into annular hoop stress.},
  doi = {10.1016/j.spinee.2010.04.015},
  institution = {Spine Service, Department of Orthopaedic Surgery, St George Hospital,
	University of New South Wales, Kogarah NSW 2217, Sydney, Australia.},
  keywords = {Arthroplasty, Replacement, instrumentation; Compressive Strength;
	Computer Simulation; Diskectomy, methods; Finite Element Analysis;
	Humans; Intervertebral Disc Displacement, physiopathology/surgery;
	Intervertebral Disc, physiopathology/surgery; Lumbar Vertebrae, surgery;
	Materials Testing; Prosthesis Design; Prosthesis Failure; Recovery
	of Function; Stress, Mechanical; Weight-Bearing, physiology},
  language = {eng},
  medline-pst = {ppublish},
  owner = {goshng},
  pii = {S1529-9430(10)00311-6},
  pmid = {20547110},
  review = {From a search for simulation of the von mises fisher distribution},
  timestamp = {2012.05.10},
  url = {http://dx.doi.org/10.1016/j.spinee.2010.04.015}
}

@ARTICLE{Zhang2009,
  author = {Zhang, Fan and Hancock, Edwin R. and Goodlett, Casey and Gerig, Guido},
  title = {Probabilistic white matter fiber tracking using particle filtering
	and von Mises-Fisher sampling.},
  journal = {Med Image Anal},
  year = {2009},
  volume = {13},
  pages = {5--18},
  number = {1},
  month = {Feb},
  __markedentry = {[goshng:6]},
  abstract = {Standard particle filtering technique have previously been applied
	to the problem of fiber tracking by Brun et al. [Brun, A., Bjornemo,
	M., Kikinis, R., Westin, C.F., 2002. White matter tractography using
	sequential importance sampling. In: Proceedings of the ISMRM Annual
	Meeting, p. 1131] and Bjornemo et al. [Bjornemo, M., Brun, A., Kikinis,
	R., Westin, C.F., 2002. Regularized stochastic white matter tractography
	using diffusion tensor MRI, In: Proc. MICCAI, pp. 435-442]. However,
	these previous attempts have not utilised the full power of the technique,
	and as a result the fiber paths were tracked in a goal directed way.
	In this paper, we provide an advanced technique by presenting a fast
	and novel probabilistic method for white matter fiber tracking in
	diffusion weighted MRI (DWI), which takes advantage of the weighting
	and resampling mechanism of particle filtering. We formulate fiber
	tracking using a non-linear state space model which captures both
	smoothness regularity of the fibers and the uncertainties in the
	local fiber orientations due to noise and partial volume effects.
	Global fiber tracking is then posed as a problem of particle filtering.
	To model the posterior distribution, we classify voxels of the white
	matter as either prolate or oblate tensors. We then construct the
	orientation distributions for prolate and oblate tensors separately.
	Finally, the importance density function for particle filtering is
	modeled using the von Mises-Fisher distribution on a unit sphere.
	Fast and efficient sampling is achieved using Ulrich-Wood's simulation
	algorithm. Given a seed point, the method is able to rapidly locate
	the globally optimal fiber and also provides a probability map for
	potential connections. The proposed method is validated and compared
	to alternative methods both on synthetic data and real-world brain
	MRI datasets.},
  doi = {10.1016/j.media.2008.05.001},
  institution = {Department of Computer Science, University of York, York YO10 5DD,
	UK. zfan@cs.york.ac.uk},
  keywords = {Algorithms; Artificial Intelligence; Brain, cytology; Computer Simulation;
	Data Interpretation, Statistical; Diffusion Magnetic Resonance Imaging,
	methods; Humans; Image Enhancement, methods; Image Interpretation,
	Computer-Assisted, methods; Models, Neurological; Models, Statistical;
	Nerve Fibers, Myelinated, ultrastructure; Pattern Recognition, Automated,
	methods; Reproducibility of Results; Sensitivity and Specificity;
	Signal Processing, Computer-Assisted},
  language = {eng},
  medline-pst = {ppublish},
  owner = {goshng},
  pii = {S1361-8415(08)00053-4},
  pmid = {18602332},
  review = {From a search for simulation of the von mises fisher distribution},
  timestamp = {2012.05.10},
  url = {http://dx.doi.org/10.1016/j.media.2008.05.001}
}

@comment{jabref-meta: selector_review:}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

