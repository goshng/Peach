% This file was created with JabRef 2.3.1.
% Encoding: ISO8859_1

@ARTICLE{Carlin:1995,
  author = {Bradley P. Carlin and Siddhartha Chib},
  title = {Bayesian model choice via Markov chain Monte Carlo methods},
  journal = {J R Statist Soc B},
  year = {1995},
  volume = {57},
  pages = {473--484},
  owner = {goshng},
  timestamp = {2007.08.07}
}

@ARTICLE{Casella:1992,
  author = {George Casella and Edward I. George},
  title = {Explaining the Gibbs Sampler},
  journal = {The American Statistician},
  year = {1992},
  volume = {46},
  pages = {167--174},
  number = {3},
  abstract = {Computer-intensive algorithms, such as the Gibbs sampler, have become
	increasingly popular statistical tools, both in applied and theoretical
	work. The properties of such algorithms, however, may sometimes not
	be obvious. Here we give a simple explanation of how and why the
	Gibbs sampler works. We analytically establish its properties in
	a simple case and provide insight for more complicated cases. There
	are also a number of examples.},
  citeulike-article-id = {1270229},
  keywords = {gibbs sampler},
  priority = {2},
  url = {http://links.jstor.org/sici?sici=0003-1305%28199208%2946%3A3%3C167%3AETGS%3E2.0.CO%3B2-R}
}

@ARTICLE{Chen:2005,
  author = {Ming-Hui Chen},
  title = {Computing marginal likelihoods from a single MCMC output},
  journal = {Statistica Neerlandica},
  year = {2005},
  volume = {59},
  pages = {16--29},
  number = {1},
  note = {available at http://ideas.repec.org/a/bla/stanee/v59y2005i1p16-29.html}
}

@ARTICLE{Chib:1995,
  author = {Siddhartha Chib},
  title = {Marginal Likelihood from the Gibbs Output},
  journal = {Journal of the American Statistical Association},
  year = {1995},
  volume = {90},
  pages = {1313--1321},
  number = {432},
  abstract = {In the context of Bayes estimation via Gibbs sampling, with or without
	data augmentation, a simple approach is developed for computing the
	marginal density of the sample data (marginal likelihood) given parameter
	draws from the posterior distribution. Consequently, Bayes factors
	for model comparisons can be routinely computed as a by-product of
	the simulation. Hitherto, this calculation has proved extremely challenging.
	Our approach exploits the fact that the marginal density can be expressed
	as the prior times the likelihood function over the posterior density.
	This simple identity holds for any parameter value. An estimate of
	the posterior density is shown to be available if all complete conditional
	densities used in the Gibbs sampler have closed-form expressions.
	To improve accuracy, the posterior density is estimated at a high
	density point, and the numerical standard error of resulting estimate
	is derived. The ideas are applied to probit regression and finite
	mixture models.},
  citeulike-article-id = {831787},
  keywords = {gibbs},
  priority = {4},
  url = {http://links.jstor.org/sici?sici=0162-1459%28199512%2990%3A432%3C1313%3AMLFTGO%3E2.0.CO%3B2-2}
}

@ARTICLE{Chib:1995a,
  author = {Chib, Siddhartha and Greenberg, Edward },
  title = {Understanding the Metropolis-Hastings Algorithm},
  journal = {The American Statistician},
  year = {1995},
  volume = {49},
  pages = {327--335},
  number = {4},
  abstract = {We provide a detailed, introductory exposition of the Metropolis-Hastings
	algorithm, a powerful Markov chain method to simulate multivariate
	distributions. A simple, intuitive derivation of this method is given
	along with guidance on implementation. Also discussed are two applications
	of the algorithm, one for implementing acceptance-rejection sampling
	when a blanketing function is not available and the other for implementing
	the algorithm with block-at-a-time scans. In the latter situation,
	many different algorithms, including the Gibbs sampler, are shown
	to be special cases of the Metropolis-Hastings algorithm. The methods
	are illustrated with examples.},
  citeulike-article-id = {831786},
  keywords = {code markov metropolishastings model probability review tutorial},
  url = {http://links.jstor.org/sici?sici=0003-1305%28199511%2949%3A4%3C327%3AUTMA%3E2.0.CO%3B2-2}
}

@ARTICLE{Chib:2005,
  author = {Siddhartha Chib and Ivan Jeliazkov},
  title = {Accept-reject Metropolis-Hastings sampling and marginal likelihood
	estimation},
  journal = {Statistica Neerlandica},
  year = {2005},
  volume = {59},
  pages = {30--44},
  number = {1},
  note = {available at http://ideas.repec.org/a/bla/stanee/v59y2005i1p30-44.html}
}

@ARTICLE{Chib:2001,
  author = {Siddhartha Chib and Ivan Jeliazkov},
  title = {Marginal Likelihood From the Metropolis-Hastings Output},
  journal = {Journal of the American Statistical Association},
  year = {2001},
  volume = {96},
  pages = {270--281},
  month = {March},
  note = {available at http://ideas.repec.org/a/bes/jnlasa/v96y2001mmarchp270-281.html}
}

@ARTICLE{Gelfand:1990,
  author = {Alan E. Gelfand and Adrian F. M. Smith},
  title = {Sampling-Based Approaches to Calculating Marginal Densities},
  journal = {Journal of the American Statistical Association},
  year = {1990},
  volume = {85},
  pages = {398--409},
  owner = {goshng},
  timestamp = {2007.08.07}
}

@ARTICLE{Gelman:1998,
  author = {Gelman, A. and Meng, X.},
  title = {Simulating normalizing constants: From importance sampling to bridge
	sampling to path sampling},
  journal = {Statistical Science},
  year = {1998},
  volume = {13},
  pages = {163--185},
  abstract = {Computing (ratios of) normalizing constants of probability models
	is a fundamental computational problem for many statistical and scientific
	studies. Monte Carlo simulation is an effective technique, especially
	with complex and high-dimensional models. This paper aims to bring
	to the attention of general statistical audiences of some effective
	methods originating from theoretical physics and at the same time
	to explore these methods from a more statistical perspective, through
	establishing...},
  citeulike-article-id = {1442948},
  keywords = {bayes factor intergration likelihood marginal thermodynamic}
}

@ARTICLE{Geyer:1995,
  author = {Charles J. Geyer and Elizabeth A. Thompson},
  title = {Annealing Markov Chain Monte Carlo with Applications to Ancestral
	Inference},
  journal = {Journal of the American Statistical Association},
  year = {1995},
  volume = {90},
  pages = {909--920},
  number = {431},
  owner = {goshng},
  timestamp = {2007.08.08}
}

@ARTICLE{Han:2001,
  author = {C. Han and B. P. Carlin},
  title = {Markov Chain Monte Carlo Methods for Computing Bayes Factors: A Comparative
	Review},
  journal = {Journal of the American Statistical Association},
  year = {2001},
  volume = {96},
  pages = {1122--1132},
  month = {September},
  note = {available at http://ideas.repec.org/a/bes/jnlasa/v96y2001mseptemberp1122-1132.html}
}

@ARTICLE{Lepage:2006,
  author = {Thomas Lepage and Stephan Lawi and Paul Tupper and David Bryant},
  title = {Continuous and tractable models for the variation of evolutionary
	rates.},
  journal = {Math Biosci},
  year = {2006},
  volume = {199},
  pages = {216--233},
  number = {2},
  month = {Feb},
  abstract = {We propose a continuous model for variation in the evolutionary rate
	across sites and over the phylogenetic tree. We derive exact transition
	probabilities of substitutions under this model. Changes in rate
	are modelled using the CIR process, a diffusion widely used in financial
	applications. The model directly extends the standard gamma distributed
	rates across site model, with one additional parameter governing
	changes in rate down the tree. The parameters of the model can be
	estimated directly from two well-known statistics: the index of dispersion
	and the gamma shape parameter of the rates across sites model. The
	CIR model can be readily incorporated into probabilistic models for
	sequence evolution. We provide here an exact formula for the likelihood
	of a three-taxon tree. The likelihoods of larger trees can be evaluated
	using Monte-Carlo methods.},
  doi = {10.1016/j.mbs.2005.11.002},
  keywords = {Base Sequence; Evolution, Molecular; Markov Chains; Models, Genetic;
	Monte Carlo Method; Phylogeny},
  owner = {goshng},
  pii = {S0025-5564(05)00205-1},
  pmid = {16406009},
  timestamp = {2007.08.08},
  url = {http://dx.doi.org/10.1016/j.mbs.2005.11.002}
}

@ARTICLE{Liu:1995,
  author = {J. Liu and W.H. Wong and A. Kong},
  title = {Correlation structure and convergence rate of the Gibbs sampler with
	various scans},
  journal = {J. Roy. Statist. Soc. B},
  year = {1995},
  volume = {57},
  pages = {157--169},
  number = {1},
  owner = {goshng},
  timestamp = {2007.08.08}
}

@ARTICLE{Marjoram:2003,
  author = {Paul Marjoram and John Molitor and Vincent Plagnol and Simon Tavare},
  title = {Markov chain Monte Carlo without likelihoods.},
  journal = {Proc Natl Acad Sci U S A},
  year = {2003},
  volume = {100},
  pages = {15324--15328},
  number = {26},
  month = {Dec},
  abstract = {Many stochastic simulation approaches for generating observations
	from a posterior distribution depend on knowing a likelihood function.
	However, for many complex probability models, such likelihoods are
	either impossible or computationally prohibitive to obtain. Here
	we present a Markov chain Monte Carlo method for generating observations
	from a posterior distribution without the use of likelihoods. It
	can also be used in frequentist applications, in particular for maximum-likelihood
	estimation. The approach is illustrated by an example of ancestral
	inference in population genetics. A number of open problems are highlighted
	in the discussion.},
  doi = {10.1073/pnas.0306899100},
  keywords = {Algorithms; Computer Simulation; DNA; DNA, Mitochondrial; Evolution;
	Genetics, Population; Humans; Likelihood Functions; Markov Chains;
	Models, Biological; Monte Carlo Method; Stochastic Processes},
  owner = {goshng},
  pii = {0306899100},
  pmid = {14663152},
  timestamp = {2007.08.08},
  url = {http://dx.doi.org/10.1073/pnas.0306899100}
}

@ARTICLE{Scott:2002,
  author = {S. L. Scott},
  title = {Bayesian Methods for Hidden Markov Models: Recursive Computing in
	the 21st Century},
  journal = {Journal of the American Statistical Association},
  year = {2002},
  volume = {97},
  pages = {337-351},
  month = {March},
  note = {available at http://ideas.repec.org/a/bes/jnlasa/v97y2002mmarchp337-351.html}
}

@ARTICLE{Sisson:2007,
  author = {S. A. Sisson and Y. Fan and Mark M Tanaka},
  title = {Sequential Monte Carlo without likelihoods.},
  journal = {Proc Natl Acad Sci U S A},
  year = {2007},
  volume = {104},
  pages = {1760--1765},
  number = {6},
  month = {Feb},
  abstract = {Recent new methods in Bayesian simulation have provided ways of evaluating
	posterior distributions in the presence of analytically or computationally
	intractable likelihood functions. Despite representing a substantial
	methodological advance, existing methods based on rejection sampling
	or Markov chain Monte Carlo can be highly inefficient and accordingly
	require far more iterations than may be practical to implement. Here
	we propose a sequential Monte Carlo sampler that convincingly overcomes
	these inefficiencies. We demonstrate its implementation through an
	epidemiological study of the transmission rate of tuberculosis.},
  doi = {10.1073/pnas.0607208104},
  keywords = {Algorithms; Animals; Bayes Theorem; Computer Simulation; Humans; Likelihood
	Functions; Models, Statistical; Monte Carlo Method; Tuberculosis},
  owner = {goshng},
  pii = {0607208104},
  pmid = {17264216},
  timestamp = {2007.08.08},
  url = {http://dx.doi.org/10.1073/pnas.0607208104}
}

@ARTICLE{Smith:1992,
  author = {Smith, A. F. M. and Gelfand, A. E. },
  title = {Bayesian Statistics without Tears: A Sampling-Resampling Perspective},
  journal = {The American Statistician},
  year = {1992},
  volume = {46},
  pages = {84--88},
  number = {2},
  abstract = {Even to the initiated, statistical calculations based on Bayes's Theorem
	can be daunting because of the numerical integrations required in
	all but the simplest applications. Moreover, from a teaching perspective,
	introductions to Bayesian statistics-if they are given at all-are
	circumscribed by these apparent calculational difficulties. Here
	we offer a straightforward sampling-resampling perspective on Bayesian
	inference, which has both pedagogic appeal and suggests easily implemented
	calculation strategies.},
  citeulike-article-id = {828998},
  keywords = {importancesampling},
  url = {http://links.jstor.org/sici?sici=0003-1305%28199205%2946%3A2%3C84%3ABSWTAS%3E2.0.CO%3B2-X}
}

@ARTICLE{Tierney:1994,
  author = {Tierney, Luke },
  title = {Markov Chains for Exploring Posterior Distributions},
  journal = {The Annals of Statistics},
  year = {1994},
  volume = {22},
  pages = {1701--1728},
  number = {4},
  abstract = {Several Markov chain methods are available for sampling from a posterior
	distribution. Two important examples are the Gibbs sampler and the
	Metropolis algorithm. In addition, several strategies are available
	for constructing hybrid algorithms. This paper outlines some of the
	basic methods and strategies and discusses some related theoretical
	and practical issues. On the theoretical side, results from the theory
	of general state space Markov chains can be used to obtain convergence
	rates, laws of large numbers and central limit theorems for estimates
	obtained from Markov chain methods. These theoretical results can
	be used to guide the construction of more efficient algorithms. For
	the practical use of Markov chain methods, standard simulation methodology
	provides several variance reduction techniques and also give guidance
	on the choice of sample size and allocation.},
  citeulike-article-id = {432149},
  keywords = {bayesian_mcmc diplomka mcmc probability statistics},
  url = {http://links.jstor.org/sici?sici=0090-5364%28199412%2922%3A4%3C1701%3AMCFEPD%3E2.0.CO%3B2-6}
}

@ARTICLE{Weare:2007,
  author = {Jonathan Weare},
  title = {Efficient Monte Carlo sampling by parallel marginalization.},
  journal = {Proc Natl Acad Sci U S A},
  year = {2007},
  volume = {104},
  pages = {12657--12662},
  number = {31},
  month = {Jul},
  abstract = {Markov chain Monte Carlo sampling methods often suffer from long correlation
	times. Consequently, these methods must be run for many steps to
	generate an independent sample. In this paper, a method is proposed
	to overcome this difficulty. The method utilizes information from
	rapidly equilibrating coarse Markov chains that sample marginal distributions
	of the full system. This is accomplished through exchanges between
	the full chain and the auxiliary coarse chains. Results of numerical
	tests on the bridge sampling and filtering/smoothing problems for
	a stochastic differential equation are presented.},
  doi = {10.1073/pnas.0705418104},
  owner = {goshng},
  pii = {0705418104},
  pmid = {17640896},
  timestamp = {2007.08.31},
  url = {http://dx.doi.org/10.1073/pnas.0705418104}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

